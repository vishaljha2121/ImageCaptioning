{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ModelTrain.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sit8b7aQtaSq",
        "outputId": "ea8ee595-f9e1-45e9-8f96-72a81c772569"
      },
      "source": [
        "!pip install keras==1.2.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==1.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/3e/9926ce5c678b7a7978724a2ecf24857d89a415d152b8d3443e6d45c228b2/Keras-1.2.2.tar.gz (175kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 5.4MB/s \n",
            "\u001b[?25hCollecting theano\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6b/97/bcd5654ba60f35f180931afabbd3b4c46c0379852f961c7a2819ff897f5d/Theano-1.0.5.tar.gz (2.8MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8MB 31.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==1.2.2) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from keras==1.2.2) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from theano->keras==1.2.2) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from theano->keras==1.2.2) (1.4.1)\n",
            "Building wheels for collected packages: keras, theano\n",
            "  Building wheel for keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras: filename=Keras-1.2.2-cp37-none-any.whl size=209602 sha256=43a1cffabac3543c1c499edf0f75a31cff1cc7485d0e14553947e0fb63cd6dbb\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/07/cf/b32db0a8d243b2fd6759d5d7cb650aa20670b2b740209cbf7e\n",
            "  Building wheel for theano (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for theano: filename=Theano-1.0.5-cp37-none-any.whl size=2668111 sha256=4403192dfb03e855a1f1781cbc3263f1ceba9cf98bd69a3fff06178e0fd37d9c\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/40/74/3a0b7d937890c66c4373120117ebf4ba99f4889b4a0a6a810c\n",
            "Successfully built keras theano\n",
            "Installing collected packages: theano, keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-1.2.2 theano-1.0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAbRQd5F0n9n",
        "outputId": "2d285b03-7366-4ea7-f3cb-ebc44be9ecc8"
      },
      "source": [
        "!pip install tensorflow==1.13.2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.13.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/70/45d3b9fab768215a2055c7819d39547a4b0b7401b4583094068741aff99b/tensorflow-1.13.2-cp37-cp37m-manylinux1_x86_64.whl (92.7MB)\n",
            "\u001b[K     |████████████████████████████████| 92.7MB 31kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (0.36.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (0.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (0.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (1.34.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (3.12.4)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (1.15.0)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 31.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (1.19.5)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 29.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.2) (57.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.2) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (1.0.1)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/03/b7e605db4a57c0f6fba744b11ef3ddf4ddebcada35022927a2b5fc623fdf/mock-4.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.13.2) (1.5.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (4.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (3.4.1)\n",
            "\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 1.13.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-applications, tensorboard, mock, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "  Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Found existing installation: tensorflow 2.5.0\n",
            "    Uninstalling tensorflow-2.5.0:\n",
            "      Successfully uninstalled tensorflow-2.5.0\n",
            "Successfully installed keras-applications-1.0.8 mock-4.0.3 tensorboard-1.13.1 tensorflow-1.13.2 tensorflow-estimator-1.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGbjH4fxslUM"
      },
      "source": [
        "import glob\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pickle\n",
        "\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Embedding, TimeDistributed, Dense, RepeatVector, Merge, Activation, Flatten\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.layers.wrappers import Bidirectional\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.preprocessing import image\n",
        "\n",
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYZJ0TVqxABt"
      },
      "source": [
        "file_location_caption = '/content/Flickr8k.token.txt'\n",
        "file_location_caption_unique = '/content/unique_captions.p'\n",
        "file_location_training_data = '/content/flickr_8k_train_dataset.txt'\n",
        "\n",
        "file_location_train_encode = '/content/encoded_images_train.p'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtrxYJOLwy_N"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQolP5jPw5eM"
      },
      "source": [
        "captions = open(file_location_caption, 'r').read().strip().split('\\n')\n",
        "unique = pickle.load(open(file_location_caption_unique, \"rb\"))\n",
        "\n",
        "train_data_encode = pickle.load(open(file_location_train_encode, 'rb'))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRUY8ygqzYZu"
      },
      "source": [
        "word2idx = {val:index for index, val in enumerate(unique)}\n",
        "idx2word = {index:val for index, val in enumerate(unique)}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04jcl5MBzkCa"
      },
      "source": [
        "max_cap_length = 40\n",
        "vocab_size = 8256"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9QmGcNBxuKr"
      },
      "source": [
        "dictionary_captions = {}\n",
        "for i, row in enumerate(captions):\n",
        "    row = row.split('\\t')\n",
        "    row[0] = row[0][:len(row[0])-2]\n",
        "    if row[0] in dictionary_captions:\n",
        "        dictionary_captions[row[0]].append(row[1])\n",
        "    else:\n",
        "        dictionary_captions[row[0]] = [row[1]]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMNoDehlt-5f"
      },
      "source": [
        "def data_generator(batch_size= 64):\n",
        "    partial_captions = []\n",
        "    next_word = []\n",
        "    images= []\n",
        "\n",
        "    df = pd.read_csv(file_location_training_data, delimiter='\\t')\n",
        "    df = df.sample(frac=1)\n",
        "    iter = df.iterrows()\n",
        "\n",
        "    c = []\n",
        "    imgs = []\n",
        "\n",
        "    for i in range(df.shape[0]):\n",
        "        x = next(iter)\n",
        "        c.append(x[1][1])\n",
        "        imgs.append(x[1][0])\n",
        "\n",
        "    count = 0\n",
        "    while True:\n",
        "        for idx, text in enumerate(c):\n",
        "            current_image = train_data_encode[imgs[idx]]\n",
        "\n",
        "            for i in range(len(text.split()) - 1):\n",
        "                count += 1\n",
        "\n",
        "                partial = [word2idx[txt] for txt in text.split()[:i+1]]\n",
        "                partial_captions.append(partial)\n",
        "\n",
        "                n = np.zeros(vocab_size)\n",
        "                n[word2idx[text.split()[i+1]]] = 1\n",
        "                next_word.append(n)\n",
        "\n",
        "                images.append(current_image)\n",
        "\n",
        "                if count >= batch_size:\n",
        "                    next_word = np.asarray(next_word)\n",
        "                    images = np.asarray(images)\n",
        "                    partial_captions = sequence.pad_sequences(partial_captions, maxlen=max_cap_length, padding='post')\n",
        "                    yield[[images, partial_captions], next_word]\n",
        "\n",
        "                    partial_captions = []\n",
        "                    next_word = []\n",
        "                    images = []\n",
        "                    count = 0"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7aaZZLauUXy",
        "outputId": "3d0ee3b7-aa33-4430-ac3c-0ee7e441b41e"
      },
      "source": [
        "embedding_size = 300\n",
        "\n",
        "image_model = Sequential([\n",
        "        Dense(embedding_size, input_shape=(2048,), activation='relu'),\n",
        "        RepeatVector(max_cap_length)\n",
        "    ])\n",
        "\n",
        "caption_model = Sequential([\n",
        "        Embedding(vocab_size, embedding_size, input_length=max_cap_length),\n",
        "        LSTM(256, return_sequences=True),\n",
        "        TimeDistributed(Dense(300))\n",
        "    ])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1029: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiXcBQ6l1-3g"
      },
      "source": [
        "model = Sequential([\n",
        "        Merge([image_model, caption_model], mode='concat', concat_axis=1),\n",
        "        Bidirectional(LSTM(256, return_sequences=False)),\n",
        "        Dense(vocab_size),\n",
        "        Activation('softmax')\n",
        "    ])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics= ['accuracy'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM-6Yuj1736U",
        "outputId": "285bbc3c-612c-46f4-b37e-998b8a0701f7"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "____________________________________________________________________________________________________\n",
            "Layer (type)                     Output Shape          Param #     Connected to                     \n",
            "====================================================================================================\n",
            "dense_1 (Dense)                  (None, 300)           614700                                       \n",
            "____________________________________________________________________________________________________\n",
            "repeatvector_1 (RepeatVector)    (None, 40, 300)       0                                            \n",
            "____________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)          (None, 40, 300)       2476800                                      \n",
            "____________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                    (None, 40, 256)       570368                                       \n",
            "____________________________________________________________________________________________________\n",
            "timedistributed_1 (TimeDistribut (None, 40, 300)       77100                                        \n",
            "____________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional)  (None, 512)           1140736     merge_1[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "dense_3 (Dense)                  (None, 8256)          4235328     bidirectional_1[0][0]            \n",
            "____________________________________________________________________________________________________\n",
            "activation_1 (Activation)        (None, 8256)          0           dense_3[0][0]                    \n",
            "====================================================================================================\n",
            "Total params: 9,115,032\n",
            "Trainable params: 9,115,032\n",
            "Non-trainable params: 0\n",
            "____________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dH8ZhFCF75r_",
        "outputId": "6a0a74c0-5138-46bf-f6a9-aa03a1e9373b"
      },
      "source": [
        "model.fit_generator(data_generator(batch_size=512), samples_per_epoch=25545, nb_epoch=1, verbose=1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "25600/25545 [==============================] - 870s - loss: 5.3205 - acc: 0.1573    \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1573: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
            "  warnings.warn('Epoch comprised more than '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f43415ce490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVLm8iNIN2sz",
        "outputId": "798bd9f5-2828-4884-cf74-2ce42a39485f"
      },
      "source": [
        "model.fit_generator(data_generator(batch_size=512), samples_per_epoch=35545, nb_epoch=1, verbose=1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "35840/35545 [==============================] - 1239s - loss: 5.1103 - acc: 0.1927  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1573: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
            "  warnings.warn('Epoch comprised more than '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4341a2a210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riXAsQxYTSOe",
        "outputId": "3dd8d298-fb46-4ba8-d7ba-3a5e438c2eef"
      },
      "source": [
        "model.fit_generator(data_generator(batch_size=1024), samples_per_epoch=45545, nb_epoch=1, verbose=1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "46080/45545 [==============================] - 1577s - loss: 4.9317 - acc: 0.2271   \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1573: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
            "  warnings.warn('Epoch comprised more than '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f43415fb910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsxgGj3jZhUO",
        "outputId": "da13b628-8979-4067-a5fc-28d456264f2e"
      },
      "source": [
        "model.fit_generator(data_generator(batch_size=1024), samples_per_epoch=55545, nb_epoch=1, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "52224/55545 [===========================>..] - ETA: 113s - loss: 4.8086 - acc: 0.2424"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7bnF2g-Zlxv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}